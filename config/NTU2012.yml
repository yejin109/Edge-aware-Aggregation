alpha: 0.1
lamda: 0.5
dropout_p: 0.6
inp_dropout_p: 0.2
activation: relu