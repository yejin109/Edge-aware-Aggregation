====================================================================================================
Arguments
	n_layers:2
	n_hidden:128
	dropout_p:0.6
	lamda:0.5
	alpha:0.1
	inp_dropout_p:0.2
	norm:ln
	mlp_layers:1
	activation:relu
	data:cocitation
	dataset:cora
	split:1
	label_percent:0.052
	use_exp_wt:False
	alpha_e:0
	alpha_n:0
	n_reg_weight:torch.Size([4786, 1])
	n_reg_sum:torch.Size([1434, 1])
	e_reg_weight:torch.Size([4786, 1])
	e_reg_sum:torch.Size([1579, 1])
	e:torch.Size([1579, 128])
	v:torch.Size([1434, 1433])
	input_dim:1433
	vidx:torch.Size([4786])
	eidx:torch.Size([4786])
	ve_lists:torch.Size([4786, 2])
	n_weight:torch.Size([1434, 1])
	e_weight:torch.Size([1579, 1])
	ne:1579
	nv:1434
	n_cls:7
	all_labels:torch.Size([1434])
	label_idx:torch.Size([143])
	labels:torch.Size([143])
	val_idx:(143,)
	test_idx:(1148,)
